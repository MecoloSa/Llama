# 爬虫与数据清洗

## 爬虫

使用beautifulsoup＋selenium的方式进行爬取

使用url分析+模拟浏览器点击的方式打开网页

## 数据清洗

### pdfminer

模型训练使用txt文件，进行pdf到txt格式的转换

使用的package：

```
import os
import re
from pdfminer.converter import PDFPageAggregator
from pdfminer.layout import LAParams, LTTextBox
from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.pdfparser import PDFParser
from pdfminer.pdfdocument import PDFDocument
from pdfminer.pdfpage import PDFTextExtractionNotAllowed, PDFPage
from io import open
```

### [GitHub - laorange/paper-assistant: 论文工具：文本复制工具 (智能删除空行空格乱码)](https://github.com/laorange/paper-assistant)

因为爬虫使用了selenium，于是看到html格式的文本工具就决定使用脚本+Chrome驱动进行整理

使用到的package：

```
import os
import pyperclip
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains
```

### [NLP数据预处理——中文文本数据清洗 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/517220095)

使用的package：

```
import re
import os
```

